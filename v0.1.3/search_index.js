var documenterSearchIndex = {"docs":
[{"location":"twosampletest/#Two-Sample-Hypothesis-Tests","page":"Two-Sample Tests","title":"Two Sample Hypothesis Tests","text":"","category":"section"},{"location":"twosampletest/#Introduction","page":"Two-Sample Tests","title":"Introduction","text":"","category":"section"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"The two-sample hypothesis testing strategies are based on Algorithm 1 by Gandy & Scott (2021)[gandyandscott2021].","category":"page"},{"location":"twosampletest/#twosample","page":"Two-Sample Tests","title":"TwoSampleTest","text":"","category":"section"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"The first basic strategy generates the treatment group","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"beginaligned\n  theta y_texttrtm sim pleft(theta yright) \n  theta_texttrtm sim Kleft(theta cdotright)\nendaligned","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"and the control group as","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"beginaligned\n  theta_textctrl y_textctrl sim pleft(theta yright) \nendaligned","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"where the test compares ","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"(theta_texttrtm  y_texttrtm)\nquadtextversusquad \n(theta_textctrl  y_textctrl)","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"TwoSampleTest","category":"page"},{"location":"twosampletest/#MCMCTesting.TwoSampleTest","page":"Two-Sample Tests","title":"MCMCTesting.TwoSampleTest","text":"TwoSampleTest(n_samples, n_mcmc_steps; n_control, n_treatment, n_mcmc_thin)\n\nTwo-sample hypothesis testing strategy. Algorithm 1 in Gandy & Scott 2021.\n\nArguments\n\nn_samples::Int: Number of samples from the joint p(θ, y) used for the computing the p-values.\nn_mcmc_steps::Int: Number of times the MCMC kernel is applied to initial sample from the joint. (Increasing this value improves the power of the test.)\n\nKeyword Arguments\n\nn_control::Int: Number of pure samples from the joint (control group). (Default: n_samples)\nn_treatment::Int: Number of samples from the MCMC kernel (treatment group). (Default: n_samples)\nn_mcmc_thin::Int: Number of thinning applied to the MCMC chain. The effect of this argument is the same as n_mcmc_steps.\n\nReturns\n\npvalues: P-value computed for each dimension of the statistic returned from statistics.\n\nRequirements\n\nThis test requires the following functions for model and kernel to be implemented:\n\nmarkovchain_transition\nsample_joint\n\nKeyword Arguments for Tests\n\nWhen calling mcmctest or seqmcmctest, this tests has an additional keyword argument:\n\ntwo_sample_test_pvalue: The p-value calculation strategy.\n\nThe default strategy is an approximate two-sample Kolmogorov-Smirnov test. Any function returning a single p-value from a two-sample hypothesis test will work. The format is as follows:\n\ntwo_sample_test_pvalue(x::AbstractVector, y::AbstractVector)::Real\n\nReferences\n\n\n\n\n\n","category":"type"},{"location":"twosampletest/#twosamplegibbs","page":"Two-Sample Tests","title":"TwoSampleGibbsTest","text":"","category":"section"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"The second strategy performs applies an additional Gibbs sampling step when generating the treatment group  as","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"beginaligned\n  theta y sim pleft(theta yright) \n  theta_texttrtm sim Kleft(theta cdotright) \n  y_texttrtm sim pleft(y mid theta_texttrtmright)\nendaligned","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"resulting in the treatment group ","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"(theta_texttrtm  y_texttrtm)","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"The control group is generated the same as TwoSampleTest.","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"To use this test, the user needs to implement the following interface for simulating from the conditional likelihood.","category":"page"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"sample_predictive","category":"page"},{"location":"twosampletest/#MCMCTesting.sample_predictive","page":"Two-Sample Tests","title":"MCMCTesting.sample_predictive","text":"sample_predictive(rng, model, θ)\n\nSample from the predictive distribution of model conditionally on θ\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nmodel: Model subject to test.\nθ: Model parameters to condition on.\n\nReturns\n\ny: Data generated from conditionally on θ from p(y|θ)\n\n\n\n\n\n","category":"function"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"TwoSampleGibbsTest","category":"page"},{"location":"twosampletest/#MCMCTesting.TwoSampleGibbsTest","page":"Two-Sample Tests","title":"MCMCTesting.TwoSampleGibbsTest","text":"TwoSampleTest(n_samples, n_mcmc_steps; n_control, n_treatment, n_mcmc_thin)\n\nTwo-sample hypothesis testing strategy with an additional Gibbs sampling step. Modified version of Algorithm 1 in Gandy & Scott 2021 for increased power.\n\nArguments\n\nn_samples::Int: Number of samples from the joint p(θ, y) used for the computing the p-values.\nn_mcmc_steps::Int: Number of times the MCMC kernel is applied to initial sample from the joint. (Increasing this value improves the power of the test.)\n\nKeyword Arguments\n\nn_control::Int: Number of pure samples from the joint (control group). (Default: n_samples)\nn_treatment::Int: Number of samples from the MCMC kernel (treatment group). (Default: n_samples)\nn_mcmc_thin::Int: Number of thinning applied to the MCMC chain. The effect of this argument is the same as n_mcmc_steps.\n\nReturns\n\npvalues: P-value computed for each dimension of the statistic returned from statistics.\n\nRequirements\n\nThis test requires the following functions for model and kernel to be implemented:\n\nmarkovchain_transition\nsample_joint\nsample_predictive\n\nKeyword Arguments for Tests\n\nWhen calling mcmctest or seqmcmctest, this tests has an additional keyword argument:\n\ntwo_sample_test_pvalue: The p-value calculation strategy.\n\nThe default strategy is an approximate two-sample Kolmogorov-Smirnov test. Any function returning a p-value to two sample groups will work. The format is as follows:\n\ntwo_sample_test_pvalue(x::AbstractVector, y::AbstractVector)::Real\n\nReferences\n\n\n\n\n\n","category":"type"},{"location":"twosampletest/#References","page":"Two-Sample Tests","title":"References","text":"","category":"section"},{"location":"twosampletest/","page":"Two-Sample Tests","title":"Two-Sample Tests","text":"[gandyandscott2021]: Gandy, A., & Scott, J. (2020). Unit testing for MCMC and other Monte Carlo methods. arXiv preprint arXiv:2001.06465.","category":"page"},{"location":"general/#General-Usage","page":"General Usage","title":"General Usage","text":"","category":"section"},{"location":"general/#Introduction","page":"General Usage","title":"Introduction","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The tests provided by MCMCTesting are frequentist hypothesis tests for testing the correctness of MCMC kernels. In particular, it compute the p-value for the null hypothesis that the MCMC kernel has the correct stationary distribution against the alternative hypothesis that it doesn't.","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Currently, MCMCTesting provide three different tests originally proposed by Gandy and Scott[gandyandscott2021]: ","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Simple Two-Sample Test\nTwo-Sample Test with an Additional Gibbs Step\nExact Rank Test","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The two-sample tests are generally applicable.  On the other hand, the exact rank test assumes that the MCMC kernel is reversible. Therefore, it can specifically be used to test reversibility.","category":"page"},{"location":"general/#Interface","page":"General Usage","title":"Interface","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The user needs to implement the following function specializations for the model and kernel subject to the test.","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"sample_joint\nmarkovchain_transition","category":"page"},{"location":"general/#MCMCTesting.sample_joint","page":"General Usage","title":"MCMCTesting.sample_joint","text":"sample_joint(rng, model)\n\nSample from the joint distribution of the prior and the predictive distribution of model.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nmodel: Model subject to test.\n\nReturns\n\nθ: Model parameter sampled from the prior p(θ).\ny: Data generated from conditionally on θ from p(y|θ)\n\n\n\n\n\n","category":"function"},{"location":"general/#MCMCTesting.markovchain_transition","page":"General Usage","title":"MCMCTesting.markovchain_transition","text":"markovchain_transition(rng, model, kernel, θ, y)\n\nPerform a single Markov chain transition of kernel on the previous state θ targeting the posterior of model conditioned on y.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nmodel: Model forming the posterior p(θ|y) conditioned on y.\nθ: Previous state of the Markov chain.\ny: Data to condition on.\n\nReturns\n\nθ′: Next state of the Markov chain.\n\n\n\n\n\n","category":"function"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Some tests might be require additional interfaces to be implemented. For an overview of how to implement these interfaces, refer to the tutorial.","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The model and kernel are then passed to MCMCTesting through the following struct:","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"TestSubject","category":"page"},{"location":"general/#MCMCTesting.TestSubject","page":"General Usage","title":"MCMCTesting.TestSubject","text":"TestSubject(model, kernel)\n\nModel and MCMC kernel obejct subject to test.\n\nArguments\n\nmodel: Model subject to test.\nkernel: MCMC kernel subject to test.\n\n\n\n\n\n","category":"type"},{"location":"general/#Simulating-a-P-Value-Through-mcmctest","page":"General Usage","title":"Simulating a P-Value Through mcmctest","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Each of the test internally run simulations and compute a single p-value through the following routine:","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"mcmctest","category":"page"},{"location":"general/#MCMCTesting.mcmctest","page":"General Usage","title":"MCMCTesting.mcmctest","text":"mcmctest([rng,] test, subject; kwargs...)\n\nSample a p-value according to test for subject\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator. (Default: Random.default_rng().)\ntest::AbstractMCMCTest: Test strategy.\nsubject::TestSubject: MCMC algorithm and model subject to test.\n\nKeyword Arguments\n\nshow_progress::Bool: Whether to show the progress bar. (Default: true.)\nstatistics: Function for computing test statistics from samples generated from the tests. (See section below for additional description.)\nCheck the documentation for the respective test strategy for additional keyword arugments.\n\nCustom Test Statistics\n\nThe statistics used for the hypothesis tests can be modified by passing a custom funciton to statistics. The default statistics are the first and second moments computed as below.\n\nstatistics = params -> vcat(params, params.^2)\n\nThe cross-interaction can also be tested by adding an additional entry as below.\n\nstatistics = params -> vcat(params, params.^2, reshape(params*params',:))\n\nBut naturally, adding more statistics increase the computational cost of computing the tests.\n\nAlso, different tests may result in different statistics being computed through the same statistics function. For example, the two-sample test strategies generate both model parameters θ and data y. Therefore, params = vcat(θ, y). On the other hand, the exac rank test only generates model parameters θ. Therefore, params = θ. Naturally, statistics can also be used to select a subset of parameters used for testing. For example, for the two-sample test strategies, if we only want to use θ for the tests, where d = length(θ) > 0, one can do the following:\n\nstatistics = params -> θ[1:d]\n\n\n\n\n\n","category":"function"},{"location":"general/#Increasing-Power-Through-seqmcmctest","page":"General Usage","title":"Increasing Power Through seqmcmctest","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"seqmcmctest (Algorithm 3[gandyandscott2021]) sequentially calls mcmctest to increase the power and ensure a low false rejection rate. Furthermore, the p-values from each component of the statistics are combined through multiple hypothesis adjustment.","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"seqmcmctest","category":"page"},{"location":"general/#MCMCTesting.seqmcmctest","page":"General Usage","title":"MCMCTesting.seqmcmctest","text":"seqmcmctest([rng,] test, subject, false_rejection_rate, samplesize; kwargs...)\n\nSequential run multiple hypothesis tests to guarantee false_rejection_rate.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\ntest::AbstractMCMCTest: Test strategy.\nsubject::TestSubject: MCMC algorithm and model subject to test.\nfalse_rejection_rate::Real: Desired false rejection rate.\nsamplesize::Int: The number of p-values used at each test iteration.\n\nKeyword Arguments\n\nsamplesize_increase: Factor of increase for the samplsize after the first test iteration turns out inconclusive. (Default: 2.0)\nshow_progress::Bool: Whether to show progress. (Default: true)\npvalue_adjustmeht::MultipleTesting.PValueAdjustment: P-value adjustment for multiple testing over the elements of the statistic. (Default: MultipleTesting.Bonferroni())\n\nAdditional keyword arguments are passed to internal calls to mcmctest.\n\nReturns\n\ntest_result::Bool: true if the null-hypothesis (the MCMC algorithm has the correct stationary distribution) wasn't rejected, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"general/#References","page":"General Usage","title":"References","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"[gandyandscott2021]: Gandy, A., & Scott, J. (2020). Unit testing for MCMC and other Monte Carlo methods. arXiv preprint arXiv:2001.06465.","category":"page"},{"location":"introduction/#MCMCTesting","page":"MCMCTesting","title":"MCMCTesting","text":"","category":"section"},{"location":"introduction/","page":"MCMCTesting","title":"MCMCTesting","text":"This package provides the MCMC testing algorithms proposed by Gandy & Scott (2021)[gandyandscott2021]. These tests can be seen as an improvement of the hypothesis testing approach proposed by Geweke [geweke2004]. Unlike simulation-based calibration (SBC; [talts2018][yaoanddomke2023][modrak2022]), these tests are more appropriate for testing the exactness of the MCMC algorithm rather than the identifiability of the models. This is because the tests focus on maximizing the power for verify the validity of individual Markov transitions instead of a set of samples. Furthermore, unlike SBC, the approach of Gandy & Scott[gandyandscott2021] is able to exactly satisfy the assumptions required for the theoretical guarantees.","category":"page"},{"location":"introduction/#References","page":"MCMCTesting","title":"References","text":"","category":"section"},{"location":"introduction/","page":"MCMCTesting","title":"MCMCTesting","text":"[gandyandscott2021]: Gandy, A., & Scott, J. (2020). Unit testing for MCMC and other Monte Carlo methods. arXiv preprint arXiv:2001.06465.","category":"page"},{"location":"introduction/","page":"MCMCTesting","title":"MCMCTesting","text":"[geweke2004]: Geweke, J. (2004). Getting it right: Joint distribution tests of posterior simulators. Journal of the American Statistical Association, 99(467), 799-804.","category":"page"},{"location":"introduction/","page":"MCMCTesting","title":"MCMCTesting","text":"[talts2018]: Talts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2018). Validating Bayesian inference algorithms with simulation-based calibration. arXiv preprint arXiv:1804.06788.","category":"page"},{"location":"introduction/","page":"MCMCTesting","title":"MCMCTesting","text":"[yaoanddomke2023]: Yao, Y., & Domke, J. (2023, November). Discriminative Calibration: Check Bayesian Computation from Simulations and Flexible Classifier. In Thirty-seventh Conference on Neural Information Processing Systems.","category":"page"},{"location":"introduction/","page":"MCMCTesting","title":"MCMCTesting","text":"[modrak2022]: Modrák, M., Moon, A. H., Kim, S., Bürkner, P., Huurre, N., Faltejsková, K., ... & Vehtari, A. (2022). Simulation-based calibration checking for Bayesian computation: The choice of test quantities shapes sensitivity. arXiv preprint arXiv:2211.02383.","category":"page"},{"location":"exactranktest/#exactrank","page":"Exact Rank Tests","title":"Exact Rank Hypothesis Tests","text":"","category":"section"},{"location":"exactranktest/#Introduction","page":"Exact Rank Tests","title":"Introduction","text":"","category":"section"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"The exact rank hypothesis testing strategy is based on Algorithm 2 by Gandy & Scott (2021)[gandyandscott2021].","category":"page"},{"location":"exactranktest/#ExactRankTest","page":"Exact Rank Tests","title":"ExactRankTest","text":"","category":"section"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"The ranks are computed by simulating a single Markov chain backwards and forward. First, a random midpoint is simulated as","category":"page"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"beginaligned\n   M sim mathrmUniform(1L)\nendaligned","category":"page"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"where L = textttn_mcmc_steps. Then, we simulate the Markov chain forward and backward as","category":"page"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"beginalignat*3\n  theta_M-l sim Kleft(theta_L-l+1 cdot right) qquad textfor l = 1 ldots M-1 \n  theta_l   sim Kleft(theta_l-1 cdot right) qquad textfor l = M+1 ldots L\nendalignat*","category":"page"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"forming the chain","category":"page"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"theta_1 ldots  theta_M ldots  theta_L","category":"page"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"The rank is the ranking of the statistics of theta_M. If the sampler and the model are correct, the rank has an uniform distribution as long as the midpoint is independently sampled.","category":"page"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"ExactRankTest","category":"page"},{"location":"exactranktest/#MCMCTesting.ExactRankTest","page":"Exact Rank Tests","title":"MCMCTesting.ExactRankTest","text":"ExactRankTest(n_samples, n_mcmc_steps; n_mcmc_thin)\n\nExact rank hypothesis testing strategy for reversible MCMC kernels. Algorithm 2 in Gandy & Scott 2021.\n\nArguments\n\nn_samples::Int: Number of ranks to be simulated.\nn_mcmc_steps::Int: Number of MCMC states to be simulated for simulating a single rank.\nn_mcmc_thin::Int: Number of thinning applied to the MCMC chain.\n\nReturns\n\npvalues: P-value computed for each dimension of the statistic returned from statistics.\n\nRequirements\n\nThis test requires the following functions for model and kernel to be implemented:\n\nmarkovchain_transition\nsample_joint\n\nFurthermore, this test explicitly assumes the following\n\nkernel is reversible.\n\nApplying this tests to an irreversible kernel will result in false negatives even if its stationary distribution is correct.\n\nKeyword Arguments for Tests\n\nWhen calling mcmctest or seqmcmctest, this tests has an additional keyword argument:\n\nuniformity_test_pvalue: The p-value calculation strategy.\n\nThe default strategy is an chi^2 test. Any function returning a single p-value from a uniformity hypothesis test will work. The format is as follows:\n\nuniformity_test_pvalue(x::AbstractVector)::Real\n\nReferences\n\n\n\n\n\n","category":"type"},{"location":"exactranktest/#References","page":"Exact Rank Tests","title":"References","text":"","category":"section"},{"location":"exactranktest/","page":"Exact Rank Tests","title":"Exact Rank Tests","text":"[gandyandscott2021]: Gandy, A., & Scott, J. (2020). Unit testing for MCMC and other Monte Carlo methods. arXiv preprint arXiv:2001.06465.","category":"page"},{"location":"","page":"MCMCTesting","title":"MCMCTesting","text":"CurrentModule = MCMCTesting","category":"page"},{"location":"#MCMCTesting","page":"MCMCTesting","title":"MCMCTesting","text":"","category":"section"},{"location":"","page":"MCMCTesting","title":"MCMCTesting","text":"Documentation for MCMCTesting.","category":"page"},{"location":"","page":"MCMCTesting","title":"MCMCTesting","text":"","category":"page"},{"location":"","page":"MCMCTesting","title":"MCMCTesting","text":"#@autodocs #Modules = [MCMCTesting] #","category":"page"},{"location":"example/#tutorial","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"example/#Problem-Setup","page":"Getting Started","title":"Problem Setup","text":"","category":"section"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"Let's consider a simple Normal-Normal model with a shared scale:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"beginaligned\ntheta sim mathrmnormalleft(0   sigma^2right) \ny      sim mathrmnormalleft(mu sigma^2right)\nendaligned","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"The joint log-likelihood can be implemented as follows:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"using Random\nusing Distributions\n\nstruct Model\n    σ::Float64\n    y::Float64\nend\n\nfunction logdensity(model::Model, θ)\n    σ, y = model.σ, model.y\n    logpdf(Normal(0, σ), only(θ)) + logpdf(Normal(0, σ), y)\nend\nnothing","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"For sampling from the posterior, a simple Gibbs sampling strategy is possible:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"struct Gibbs end\n\nfunction step(rng::Random.AbstractRNG, model::Model, ::Gibbs, θ)\n    y = model.y\n    σ = model.σ\n    rand(rng, MvNormal([y]/2, σ))\nend\nnothing","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"We could also use the classic symmetric random walk Metropolis-Hastings sampler:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"struct RWMH\n    σ::Float64\nend\n\nfunction step(rng::Random.AbstractRNG, model::Model, kernel::RWMH, θ)\n    σ = kernel.σ\n    θ′ = rand(rng, MvNormal(θ, σ))\n    ℓπ = logdensity(model, θ)\n    ℓπ′ = logdensity(model, θ′)\n    ℓα = ℓπ′ - ℓπ\n    if log(rand(rng)) ≤ ℓα\n        θ′\n    else\n        θ\n    end\nend\nnothing","category":"page"},{"location":"example/#Testing-the-Gibbs-Sampler","page":"Getting Started","title":"Testing the Gibbs Sampler","text":"","category":"section"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"All of the functionalities of MCMCTesting assume that we can sample from the joint distribution p(theta y). This is done by as follows:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"using MCMCTesting\n\nfunction MCMCTesting.sample_joint(rng::Random.AbstractRNG, model::Model)\n    σ = model.σ\n    θ = rand(rng, Normal(0, σ))\n    y = rand(rng, Normal(θ, σ))\n    [θ], [y]\nend\nnothing","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"The Gibbs sampler can be connected to MCMCTesting by implementing the following:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"using Accessors\n\nfunction MCMCTesting.markovchain_transition(\n    rng::Random.AbstractRNG, model::Model, kernel, θ, y\n)\n    model′ = @set model.y = only(y)\n    step(rng, model′, kernel, θ)\nend\nnothing","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"Let's check that the implementation is correct by ","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"model = Model(1., 1.)\nkernel = Gibbs()\ntest = TwoSampleTest(100, 100)\nsubject = TestSubject(model, kernel)\nseqmcmctest(test, subject, 0.0001, 100; show_progress=false)","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"true means that the tests have passed. Now, let's consider two erroneous implementations:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"struct GibbsWrongMean end\n\nfunction step(rng::Random.AbstractRNG, model::Model, ::GibbsWrongMean, θ)\n    y = model.y\n    σ = model.σ\n    rand(rng, MvNormal([y], σ/2))\nend\n\nstruct GibbsWrongVar end\n\nfunction step(rng::Random.AbstractRNG, model::Model, ::GibbsWrongVar, θ)\n    y = model.y\n    σ = model.σ\n    rand(rng, MvNormal([y/2], 2*σ))\nend\nnothing","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"The kernel with a wrong mean fails:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"kernel = GibbsWrongMean()\nsubject = TestSubject(model, kernel)\nseqmcmctest(test, subject, 0.0001, 100; show_progress=false)","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"and so does the one with the wrong variance:","category":"page"},{"location":"example/","page":"Getting Started","title":"Getting Started","text":"kernel = GibbsWrongVar()\nsubject = TestSubject(model, kernel)\nseqmcmctest(test, subject, 0.0001, 100; show_progress=false)","category":"page"},{"location":"example/#Visualizing-the-ranks","page":"Getting Started","title":"Visualizing the ranks","text":"","category":"section"}]
}
